{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations for User ID user1:\n",
      "item4    7\n",
      "item5    6\n",
      "item2    2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# Sample Data (replace this with your actual data)\n",
    "user_item_matrix = pd.DataFrame({\n",
    "    'user1': [1, 0, 3, 0, 0],\n",
    "    'user2': [0, 2, 0, 4, 5],\n",
    "    'user3': [5, 0, 0, 0, 1],\n",
    "    'user4': [0, 0, 0, 3, 0],\n",
    "    'user5': [2, 0, 1, 0, 0]\n",
    "}, index=['item1', 'item2', 'item3', 'item4', 'item5'])\n",
    "\n",
    "# Replace NaN with 0 for simplicity (you may handle missing values more appropriately)\n",
    "user_item_matrix = user_item_matrix.fillna(0)\n",
    "\n",
    "# Function to get similar users\n",
    "def get_similar_users(user_item_matrix, user_id, k=5):\n",
    "    # Use cosine similarity to find similar users\n",
    "    similarities = cosine_similarity(user_item_matrix.T)  # Transpose the matrix\n",
    "    \n",
    "    # Get the index of the target user\n",
    "    user_index = user_item_matrix.columns.get_loc(user_id)\n",
    "    \n",
    "    # Get the top k similar users (excluding the target user itself)\n",
    "    similar_users = NearestNeighbors(n_neighbors=min(k+1, len(user_item_matrix.columns)), metric='cosine')\n",
    "    similar_users.fit(similarities)\n",
    "    \n",
    "    distances, indices = similar_users.kneighbors(similarities[:, user_index].reshape(1, -1))\n",
    "    \n",
    "    # Exclude the first element, as it is the target user itself\n",
    "    similar_user_indices = indices[0][1:]\n",
    "    \n",
    "    return user_item_matrix.columns[similar_user_indices]\n",
    "\n",
    "# Function to recommend items to a user based on similar users\n",
    "def recommend_items(user_item_matrix, user_id, similar_users):\n",
    "    # Find items that the similar users liked but the target user hasn't interacted with\n",
    "    user_interactions = user_item_matrix[user_id]\n",
    "    similar_users_interactions = user_item_matrix[similar_users].sum(axis=1)\n",
    "    \n",
    "    # Filter out items already interacted with by the target user\n",
    "    recommendations = similar_users_interactions[user_interactions == 0]\n",
    "    \n",
    "    # Sort the recommendations by interaction strength\n",
    "    recommendations = recommendations.sort_values(ascending=False)\n",
    "    \n",
    "    return recommendations\n",
    "\n",
    "# Example usage\n",
    "target_user_id = 'user1'  # Replace with the actual user ID\n",
    "similar_users = get_similar_users(user_item_matrix, target_user_id)\n",
    "recommendations = recommend_items(user_item_matrix, target_user_id, similar_users)\n",
    "\n",
    "print(f\"Recommendations for User ID {target_user_id}:\\n{recommendations}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import spotipy\n",
    "import spotipy.oauth2 as oauth2\n",
    "from spotipy.oauth2 import SpotifyOAuth,SpotifyClientCredentials\n",
    "import yaml\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import multiprocessing as mp\n",
    "import time\n",
    "import random\n",
    "import datetime\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "#from skimage import io\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('1M_unique_processed_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66243, 31)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop_duplicates(inplace=True)\n",
    "df.drop_duplicates(subset='track_uri',inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns to drop\n",
    "columns_to_drop = ['name', 'num_holdouts', 'pid', 'num_tracks', 'num_samples', 'pos', 'time_signature']\n",
    "\n",
    "# Drop the specified columns\n",
    "df.drop(columns=columns_to_drop, inplace=True)\n",
    "# Dropping rows with missing values in specified columns\n",
    "columns_to_keep = ['artist_name', 'track_name', 'artist_pop', 'popularity','release_date']\n",
    "df = df.dropna(subset=columns_to_keep)\n",
    "\n",
    "# Selecting only the columns of interest\n",
    "df = df[columns_to_keep]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['release_date']=pd.to_datetime(df['release_date'], errors='coerce')\n",
    "df['year'] = df['release_date'].dt.year\n",
    "df.dropna(subset=['year'], inplace=True)\n",
    "\n",
    "df.drop(columns=['release_date'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17476, 5)\n"
     ]
    }
   ],
   "source": [
    "df = df.sample(frac=0.3, random_state=42)  # Adjust fraction size as needed\n",
    "\n",
    "# Display the shape of the sampled dataset\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "artist_name    0\n",
       "track_name     0\n",
       "artist_pop     0\n",
       "popularity     0\n",
       "year           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'n_clusters': 4, 'init': 'k-means++', 'max_iter': 300}\n",
      "Best Silhouette Score: 0.5272259741760454\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# One-hot encode the 'artist_name' column\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "artist_encoded = encoder.fit_transform(df[['artist_name']])\n",
    "\n",
    "# Concatenate the one-hot encoded array with the 'popularity' column\n",
    "popularity_column = df[['popularity']].values\n",
    "year_column = df[['year']].values\n",
    "\n",
    "X = np.concatenate([artist_encoded, popularity_column,year_column], axis=1)\n",
    "\n",
    "\n",
    "# Initialize variables to store best parameters and score\n",
    "best_params = None\n",
    "best_score = -1  # Set initial best score to a low value\n",
    "\n",
    "# Iterate through parameter combinations\n",
    "for n_clusters in [4]:\n",
    "    for init in ['k-means++', 'random']:\n",
    "        for max_iter in [300, 500, 800]:\n",
    "            # Create KMeans model with current parameters\n",
    "            kmeans = KMeans(n_clusters=n_clusters, init=init, max_iter=max_iter, random_state=42)\n",
    "\n",
    "            # Fit the model to the data\n",
    "            kmeans.fit(X)\n",
    "\n",
    "            # Calculate silhouette score\n",
    "            score = silhouette_score(X, kmeans.labels_)\n",
    "\n",
    "            # Update best parameters and score if necessary\n",
    "            if score > best_score:\n",
    "                best_params = {'n_clusters': n_clusters, 'init': init, 'max_iter': max_iter}\n",
    "                best_score = score\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Silhouette Score:\", best_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    }
   ],
   "source": [
    "# Get the best parameters\n",
    "best_params \n",
    "\n",
    "# Initialize KMeans with the best parameters\n",
    "best_kmeans = KMeans(n_clusters=best_params['n_clusters'], \n",
    "                     init=best_params['init'], \n",
    "                     max_iter=best_params['max_iter'], \n",
    "                     random_state=42)\n",
    "\n",
    "# Fit the best KMeans model to the data\n",
    "best_kmeans.fit(X)\n",
    "\n",
    "# Assign clusters to the data using the best model\n",
    "df['cluster'] = best_kmeans.labels_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spotify API credentials\n",
    "client_id = 'd4eec2244fb2416ebce8ec488b1f9587'\n",
    "client_secret = '0cf3c26eca6244e796a10a847dc11f17'\n",
    "\n",
    "auth_manager = SpotifyClientCredentials(client_id=client_id, client_secret=client_secret)\n",
    "sp = spotipy.client.Spotify(auth_manager=auth_manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract track ID from Spotify URL\n",
    "spotify_url = \"https://open.spotify.com/track/2aPTvyE09vUCRwVvj0I8WK?si=7b06b8f1012041ce\"\n",
    "track_id = spotify_url.split('/')[-1].split('?')[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the track information\n",
    "track_info = sp.track(track_id)\n",
    "\n",
    "# Extract track popularity\n",
    "track_popularity = track_info['popularity']\n",
    "\n",
    "# Get the artist information\n",
    "artist_id = track_info['artists'][0]['id']\n",
    "artist_info = sp.artist(artist_id)\n",
    "\n",
    "# Extract artist popularity\n",
    "artist_popularity = artist_info['popularity']\n",
    "\n",
    "release_date = track_info['album']['release_date']\n",
    "release_year = int(release_date.split('-')[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                artist_name            track_name    year\n",
      "285991              Tantric          Down And Out  2008.0\n",
      "272799      No Te Va Gustar                 Clara  2002.0\n",
      "152514  Christopher Jackson         One Last Time  2015.0\n",
      "127687       Arctic Monkeys         Dancing Shoes  2006.0\n",
      "84204       Whitney Houston  You Light Up My Life  2002.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but OneHotEncoder was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Concatenate the selected features of the given track\n",
    "track_features = np.concatenate([encoder.transform([[artist_info['name']]]), [[track_popularity, release_year]]], axis=1)\n",
    "\n",
    "# Find the cluster of the given track based on selected features\n",
    "track_cluster = best_kmeans.predict(track_features)[0]\n",
    "\n",
    "# Select similar tracks from the same cluster\n",
    "num_recommendations = 5  # Adjust the number of recommendations\n",
    "similar_tracks = df[df['cluster'] == track_cluster].sample(num_recommendations)\n",
    "\n",
    "# Show the recommended tracks\n",
    "recommended_tracks = similar_tracks[['artist_name', 'track_name', 'year']]\n",
    "print(recommended_tracks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      artist_name                          track_name  release_year\n",
      "29365  A$AP Rocky                            Pharsyde           NaN\n",
      "30054  A$AP Rocky                       Better Things           NaN\n",
      "29425  A$AP Rocky  Lord Pretty Flacko Jodye 2 (LPFJ2)           NaN\n"
     ]
    }
   ],
   "source": [
    "def get_recommendations(track_url):\n",
    "    # Extract the track ID from the URL\n",
    "    track_id = track_url.split('/')[-1].split('?')[0]\n",
    "\n",
    "    # Get the track information\n",
    "    track_info = sp.track(track_id)\n",
    "\n",
    "    # Extract the artist name\n",
    "    artist_name = track_info['artists'][0]['name']\n",
    "\n",
    "    # Filter the dataset for tracks by the extracted artist\n",
    "    artist_tracks = df[df['artist_name'] == artist_name]\n",
    "\n",
    "    # Get recommendations based on the artist's tracks\n",
    "    num_recommendations = 3  # Adjust the number as needed\n",
    "    recommendations = artist_tracks.sample(num_recommendations)\n",
    "\n",
    "    # If 'release_date' is available, add 'release_year'; otherwise, set 'release_year' to NaN\n",
    "    if 'release_date' in recommendations.columns:\n",
    "        recommendations['release_date'] = recommendations['release_date'].astype(str)\n",
    "        recommendations['release_year'] = recommendations['release_date'].str.split('-', expand=True)[0].astype(float)\n",
    "    else:\n",
    "        recommendations['release_year'] = float('nan')\n",
    "\n",
    "    return recommendations[['artist_name', 'track_name', 'release_year']]\n",
    "\n",
    "# Example usage\n",
    "spotify_track_url = 'https://open.spotify.com/track/2aPTvyE09vUCRwVvj0I8WK?si=7b06b8f1012041ce'\n",
    "recommendations = get_recommendations(spotify_track_url)\n",
    "print(recommendations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Klusters_model.joblib']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(best_kmeans, 'Klusters_model.joblib')\n",
    "\n",
    "# To load the model later\n",
    "#loaded_model = joblib.load('Klusters_model.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the saved KMeans model\n",
    "loaded_kmeans_model = joblib.load('Klusters_model.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but OneHotEncoder was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "new_track_features = np.concatenate([encoder.transform([[artist_info['name']]]), [[track_popularity]]], axis=1)\n",
    "\n",
    "# Predict the cluster of the new track\n",
    "new_track_cluster = loaded_kmeans_model.predict(new_track_features)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          artist_name                                      track_name\n",
      "212251            Nas                                     Nas Is Like\n",
      "26380    Travis Scott                                            3500\n",
      "42887           gnash       i hate u, i love u (feat. olivia o'brien)\n",
      "232052   Cast Of Rent  Seasons Of Love - From The Motion Picture RENT\n",
      "93887   Darius Rucker                                   If I Told You\n"
     ]
    }
   ],
   "source": [
    "num_recommendations = 5  # Adjust the number of recommendations\n",
    "similar_tracks_new = df[df['cluster'] == new_track_cluster].sample(num_recommendations)\n",
    "\n",
    "# Show the recommended tracks for the new track\n",
    "recommended_tracks_new = similar_tracks_new[['artist_name', 'track_name']]\n",
    "print(recommended_tracks_new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      artist_name        track_name\n",
      "29368  A$AP Rocky     Electric Body\n",
      "29461  A$AP Rocky  F**kin' Problems\n",
      "30003  A$AP Rocky   Ghetto Symphony\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but OneHotEncoder was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def get_recommendations(track_url, kmeans_model):\n",
    "    # Extract the track ID from the URL\n",
    "    track_id = track_url.split('/')[-1].split('?')[0]\n",
    "\n",
    "    # Get the track information\n",
    "    track_info = sp.track(track_id)\n",
    "\n",
    "    # Extract the artist name and track popularity\n",
    "    artist_name = track_info['artists'][0]['name']\n",
    "    track_popularity = track_info['popularity']\n",
    "\n",
    "    # Concatenate the features of the given track\n",
    "    track_features = np.concatenate([encoder.transform([[artist_name]]), [[track_popularity]]], axis=1)\n",
    "\n",
    "    # Filter the dataset for tracks by the same artist\n",
    "    artist_tracks = df[df['artist_name'] == artist_name]\n",
    "\n",
    "    # Predict the cluster of the given track\n",
    "    track_cluster = kmeans_model.predict(track_features)[0]\n",
    "\n",
    "    # Select similar tracks from the same cluster\n",
    "    num_recommendations = 3  # Adjust the number as needed\n",
    "    similar_tracks = df[(df['cluster'] == track_cluster) & (df['artist_name'] == artist_name)].sample(num_recommendations)\n",
    "\n",
    "    return similar_tracks[['artist_name', 'track_name']]\n",
    "\n",
    "\n",
    "# Example usage\n",
    "spotify_track_url = 'https://open.spotify.com/track/2aPTvyE09vUCRwVvj0I8WK?si=7b06b8f1012041ce'\n",
    "recommendations = get_recommendations(spotify_track_url, loaded_kmeans_model)\n",
    "print(recommendations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
