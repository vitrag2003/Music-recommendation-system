{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('../Data/Spotify_with_genre_clustered.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist_name</th>\n",
       "      <th>track_name</th>\n",
       "      <th>artist_pop</th>\n",
       "      <th>popularity</th>\n",
       "      <th>genre</th>\n",
       "      <th>track_uri</th>\n",
       "      <th>artist_uri</th>\n",
       "      <th>year</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34</td>\n",
       "      <td>Preachin' To The Choir</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>6JKj9seJCshLVCfBLFp7dS</td>\n",
       "      <td>55RI2GNCfyXr0f14uIdhwd</td>\n",
       "      <td>2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2911</td>\n",
       "      <td>You Work Days I Work Nights</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.108696</td>\n",
       "      <td>2</td>\n",
       "      <td>7L7u4PrNt5WMtVI9lHWlLm</td>\n",
       "      <td>6k3UpifDbb2ox25edM5j3P</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>485</td>\n",
       "      <td>Sera</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.336957</td>\n",
       "      <td>1</td>\n",
       "      <td>12EyOqMPMyAKlKSynICAGN</td>\n",
       "      <td>2qhLqZ1pkiUl5HNrU2Nz0R</td>\n",
       "      <td>2007</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1268</td>\n",
       "      <td>Big Shit Poppin</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.206522</td>\n",
       "      <td>1</td>\n",
       "      <td>3tCDjKseLQJhShfbeg4m7K</td>\n",
       "      <td>4yBK75WVCQXej1p04GWqxH</td>\n",
       "      <td>2007</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1525</td>\n",
       "      <td>No La Voy A Engañar</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.586957</td>\n",
       "      <td>1</td>\n",
       "      <td>0UICwSsSpUt98XkeCfupFn</td>\n",
       "      <td>5bSfBBCxY8QAk4Pifveisz</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   artist_name                   track_name  artist_pop  popularity  genre  \\\n",
       "0           34       Preachin' To The Choir        0.37    0.000000      1   \n",
       "1         2911  You Work Days I Work Nights        0.29    0.108696      2   \n",
       "2          485                         Sera        0.44    0.336957      1   \n",
       "3         1268              Big Shit Poppin        0.69    0.206522      1   \n",
       "4         1525          No La Voy A Engañar        0.74    0.586957      1   \n",
       "\n",
       "                track_uri              artist_uri  year  cluster  \n",
       "0  6JKj9seJCshLVCfBLFp7dS  55RI2GNCfyXr0f14uIdhwd  2017        0  \n",
       "1  7L7u4PrNt5WMtVI9lHWlLm  6k3UpifDbb2ox25edM5j3P  2012        0  \n",
       "2  12EyOqMPMyAKlKSynICAGN  2qhLqZ1pkiUl5HNrU2Nz0R  2007        0  \n",
       "3  3tCDjKseLQJhShfbeg4m7K  4yBK75WVCQXej1p04GWqxH  2007        0  \n",
       "4  0UICwSsSpUt98XkeCfupFn  5bSfBBCxY8QAk4Pifveisz  2012        0  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "from spotipy.client import SpotifyException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_id = '6444952d25014134affbddb6854f27c7'\n",
    "client_secret = '49c9c42e4b54426785ae5856b45b719e'\n",
    "client_credentials_manager = SpotifyClientCredentials(client_id=client_id, client_secret=client_secret)\n",
    "sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fetch track info\n",
    "def get_track_info(track_name):\n",
    "    results = sp.search(q=track_name, limit=1)\n",
    "    if results['tracks']['items']:\n",
    "        track = results['tracks']['items'][0]\n",
    "        track_uri = track['uri'].split(':')[-1]  # Extracting the track URI\n",
    "        artist_name = track['artists'][0]['name']  # Extracting the artist name\n",
    "        release_date = track['album']['release_date'][:4]  # Extracting the year of release\n",
    "        popularity = track['popularity']  # Track popularity\n",
    "        artist_pop = sp.artist(track['artists'][0]['id'])['popularity']  # Artist popularity\n",
    "        return track_uri, artist_name, release_date, popularity, artist_pop\n",
    "    else:\n",
    "        return None, None, None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fetch specific audio features\n",
    "def get_audio_features(track_url):\n",
    "    audio_features = sp.audio_features([track_url])\n",
    "    if audio_features:\n",
    "        # Extracting only desired audio features\n",
    "        selected_features = {\n",
    "            'danceability': audio_features[0]['danceability'],\n",
    "            'energy': audio_features[0]['energy'],\n",
    "            'key': audio_features[0]['key'],\n",
    "            'loudness': audio_features[0]['loudness'],\n",
    "            'mode': audio_features[0]['mode'],\n",
    "            'speechiness': audio_features[0]['speechiness'],\n",
    "            'acousticness': audio_features[0]['acousticness'],\n",
    "            'instrumentalness': audio_features[0]['instrumentalness'],\n",
    "            'liveness': audio_features[0]['liveness'],\n",
    "            'valence': audio_features[0]['valence'],\n",
    "            'tempo': audio_features[0]['tempo']\n",
    "        }\n",
    "        return selected_features\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track URL: 2LKOHdMsL0K9KwcPRlJK2v\n",
      "Artist: Mr.Kitty\n",
      "Release Year: 2014\n",
      "Track Popularity: 83\n",
      "Artist Popularity: 65\n",
      "Audio Features: {'danceability': 0.585, 'energy': 0.595, 'key': 8, 'loudness': -10.444, 'mode': 1, 'speechiness': 0.0328, 'acousticness': 0.0696, 'instrumentalness': 0.266, 'liveness': 0.0837, 'valence': 0.039, 'tempo': 140.037}\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "track_name = input(\"Enter the track name: \")\n",
    "track_uri, artist_name, release_date, popularity, artist_pop = get_track_info(track_name)\n",
    "if track_uri:\n",
    "    print(\"Track URL:\", track_uri)\n",
    "    print(\"Artist:\", artist_name)\n",
    "    print(\"Release Year:\", release_date)\n",
    "    print(\"Track Popularity:\", popularity)\n",
    "    print(\"Artist Popularity:\", artist_pop)\n",
    "    audio_features = get_audio_features(track_uri)\n",
    "    if audio_features:\n",
    "        print(\"Audio Features:\", audio_features)\n",
    "    else:\n",
    "        print(\"Failed to fetch audio features.\")\n",
    "else:\n",
    "    print(\"Track not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load scaler and XGBoost model\n",
    "base_path = '../Models/'\n",
    "with open(base_path+'scaler.pkl', 'rb') as f:\n",
    "    scaler = pickle.load(f)\n",
    "\n",
    "with open(base_path+'xgb.pkl', 'rb') as f:\n",
    "    xgb_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.585</td>\n",
       "      <td>0.595</td>\n",
       "      <td>8</td>\n",
       "      <td>-10.444</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0328</td>\n",
       "      <td>0.0696</td>\n",
       "      <td>0.266</td>\n",
       "      <td>0.0837</td>\n",
       "      <td>0.039</td>\n",
       "      <td>140.037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   danceability  energy  key  loudness  mode  speechiness  acousticness  \\\n",
       "0         0.585   0.595    8   -10.444     1       0.0328        0.0696   \n",
       "\n",
       "   instrumentalness  liveness  valence    tempo  \n",
       "0             0.266    0.0837    0.039  140.037  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(audio_features, index=[0]).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess input features using scaler\n",
    "def preprocess_input(audio_features):\n",
    "    # Convert audio features to numpy array\n",
    "    # features_array = np.array(list(audio_features.values())).reshape(1, -1)\n",
    "    scaled_features = scaler.transform(pd.DataFrame(audio_features, index=[0]))\n",
    "    return scaled_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to make prediction using XGBoost model\n",
    "def predict(features):\n",
    "    return xgb_model.predict(features)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess input features\n",
    "scaled_features = preprocess_input(audio_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make prediction\n",
    "genre = predict(scaled_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Genre: Rap\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "with open(base_path+'encoder.pkl', 'rb') as f:\n",
    "    genre_map = pickle.load(f)\n",
    "print(\"Predicted Genre:\", genre_map.inverse_transform([int(genre)])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A Thousand Horses' 'Water Liars' 'Chambao' ... 'Steve Angello'\n",
      " 'Sebastian Ingrosso' 'Man Man']\n"
     ]
    }
   ],
   "source": [
    "with open(base_path+'label_encoder.pkl', 'rb') as f:\n",
    "    artist_name_map = pickle.load(f)\n",
    "    \n",
    "artists = df['artist_name'].unique()\n",
    "\n",
    "print(artist_name_map.inverse_transform(artists))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame\n",
    "data_df = pd.DataFrame({\n",
    "    \"artist_pop\": [artist_pop],\n",
    "    \"popularity\": [popularity],\n",
    "    \"year\": [release_date],\n",
    "    \"genre\": [genre],\n",
    "    # \"artist_name\": [artist_name_map.inverse_transform([artist_name])[0]]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "with open(base_path+'birch.pkl', 'rb') as f:\n",
    "    birch_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Birch Clusters: [0]\n"
     ]
    }
   ],
   "source": [
    "# Use the model to predict clusters\n",
    "cluster = birch_model.predict(data_df)\n",
    "print(\"Birch Clusters:\", cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: \"Preachin' To The Choir\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[108], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cluster_data\u001b[38;5;241m.\u001b[39miloc[similar_indices]\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m recommendations \u001b[38;5;241m=\u001b[39m \u001b[43mrecommend_tracks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcluster\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRecommendations for the track:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(recommendations[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrack_name\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124martist_name\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpopularity\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenre\u001b[39m\u001b[38;5;124m'\u001b[39m]])\n",
      "Cell \u001b[1;32mIn[108], line 15\u001b[0m, in \u001b[0;36mrecommend_tracks\u001b[1;34m(data, cluster, n_recommendations)\u001b[0m\n\u001b[0;32m     13\u001b[0m cluster_data \u001b[38;5;241m=\u001b[39m data[data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcluster\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m cluster]\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Find nearest neighbors\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m similar_indices \u001b[38;5;241m=\u001b[39m \u001b[43mfind_nearest_neighbors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcluster_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcluster\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_recommendations\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Return recommendations\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cluster_data\u001b[38;5;241m.\u001b[39miloc[similar_indices]\n",
      "Cell \u001b[1;32mIn[108], line 6\u001b[0m, in \u001b[0;36mfind_nearest_neighbors\u001b[1;34m(data, index, n_neighbors)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfind_nearest_neighbors\u001b[39m(data, index, n_neighbors\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m----> 6\u001b[0m     similarities \u001b[38;5;241m=\u001b[39m \u001b[43mcosine_similarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m:\u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[0;32m      7\u001b[0m     similar_indices \u001b[38;5;241m=\u001b[39m similarities\u001b[38;5;241m.\u001b[39margsort()[\u001b[38;5;241m-\u001b[39mn_neighbors\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m similar_indices\n",
      "File \u001b[1;32mc:\\Users\\Yuval\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:214\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    210\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    211\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    212\u001b[0m         )\n\u001b[0;32m    213\u001b[0m     ):\n\u001b[1;32m--> 214\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    224\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Yuval\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:1578\u001b[0m, in \u001b[0;36mcosine_similarity\u001b[1;34m(X, Y, dense_output)\u001b[0m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute cosine similarity between samples in X and Y.\u001b[39;00m\n\u001b[0;32m   1544\u001b[0m \n\u001b[0;32m   1545\u001b[0m \u001b[38;5;124;03mCosine similarity, or the cosine kernel, computes similarity as the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1574\u001b[0m \u001b[38;5;124;03m    Returns the cosine similarity between samples in X and Y.\u001b[39;00m\n\u001b[0;32m   1575\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1576\u001b[0m \u001b[38;5;66;03m# to avoid recursive import\u001b[39;00m\n\u001b[1;32m-> 1578\u001b[0m X, Y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_pairwise_arrays\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1580\u001b[0m X_normalized \u001b[38;5;241m=\u001b[39m normalize(X, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1581\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X \u001b[38;5;129;01mis\u001b[39;00m Y:\n",
      "File \u001b[1;32mc:\\Users\\Yuval\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:165\u001b[0m, in \u001b[0;36mcheck_pairwise_arrays\u001b[1;34m(X, Y, precomputed, dtype, accept_sparse, force_all_finite, copy)\u001b[0m\n\u001b[0;32m    156\u001b[0m     X \u001b[38;5;241m=\u001b[39m Y \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m    157\u001b[0m         X,\n\u001b[0;32m    158\u001b[0m         accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    162\u001b[0m         estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[0;32m    163\u001b[0m     )\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 165\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    166\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    167\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    168\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    169\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    170\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    173\u001b[0m     Y \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m    174\u001b[0m         Y,\n\u001b[0;32m    175\u001b[0m         accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    179\u001b[0m         estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[0;32m    180\u001b[0m     )\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m precomputed:\n",
      "File \u001b[1;32mc:\\Users\\Yuval\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\validation.py:915\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    913\u001b[0m         array \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(array, dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    914\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 915\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43m_asarray_with_order\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    916\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[0;32m    917\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    918\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[0;32m    919\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Yuval\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\_array_api.py:380\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[0;32m    378\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39marray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 380\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    382\u001b[0m \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[0;32m    383\u001b[0m \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[0;32m    384\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array)\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: \"Preachin' To The Choir\""
     ]
    }
   ],
   "source": [
    "#recommendation system\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "#find nearest neighbors using cosine similarity\n",
    "def find_nearest_neighbors(data, index, n_neighbors=5):\n",
    "    similarities = cosine_similarity(data, data[index:index+1]).flatten()\n",
    "    similar_indices = similarities.argsort()[-n_neighbors-1:-1]\n",
    "    return similar_indices\n",
    "\n",
    "# Function to recommend tracks\n",
    "def recommend_tracks(data, cluster, n_recommendations=5):\n",
    "    # Filter data for the same cluster\n",
    "    cluster_data = data[data['cluster'] == cluster]\n",
    "    # Find nearest neighbors\n",
    "    similar_indices = find_nearest_neighbors(cluster_data.drop('cluster', axis=1), 0, n_recommendations)\n",
    "    # Return recommendations\n",
    "    return cluster_data.iloc[similar_indices]\n",
    "\n",
    "# Example usage\n",
    "recommendations = recommend_tracks(df, cluster[0])\n",
    "print(\"Recommendations for the track:\")\n",
    "print(recommendations[['track_name', 'artist_name', 'popularity', 'genre']])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
